{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33a7540",
   "metadata": {},
   "source": [
    "## Example 3.3. Fire Calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045dd2c6",
   "metadata": {},
   "source": [
    "Using DataFrameReader.\n",
    "Let's read a large CSV file containing data on San Francisco Fire Department calls. \n",
    "We will define a schema for this file and use the DataFrameReader class and its methods to tell Spark what to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368a5a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.types._\r\n",
       "import org.apache.spark.sql.functions._\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6e75fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType, FloatType, BooleanType}\r\n",
       "fireSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true),StructField(UnitID,StringType,true),StructField(IncidentNumber,IntegerType,true),StructField(CallType,StringType,true),StructField(CallDate,StringType,true),StructField(WatchDate,StringType,true),StructField(CallFinalDisposition,StringType,true),StructField(AvailableDtTm,StringType,true),StructField(Address,StringType,true),StructField(City,StringType,true),StructField(Zipcode,IntegerType,true),StructField(Battalion,StringType,true),StructField(StationArea,StringType,true),StructField(Box,StringType,true),StructField(OriginalPriority,StringType,true),StructField(Priority,Strin...\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types.{StructType, StructField, StringType, IntegerType, FloatType, BooleanType};\n",
    "\n",
    "val fireSchema = StructType(Array(StructField(\"CallNumber\", IntegerType, true),\n",
    "     StructField(\"UnitID\", StringType, true),\n",
    "     StructField(\"IncidentNumber\", IntegerType, true),\n",
    "     StructField(\"CallType\", StringType, true),\n",
    "     StructField(\"CallDate\", StringType, true), \n",
    "     StructField(\"WatchDate\", StringType, true),\n",
    "     StructField(\"CallFinalDisposition\", StringType, true),\n",
    "     StructField(\"AvailableDtTm\", StringType, true),\n",
    "     StructField(\"Address\", StringType, true), \n",
    "     StructField(\"City\", StringType, true), \n",
    "     StructField(\"Zipcode\", IntegerType, true), \n",
    "     StructField(\"Battalion\", StringType, true), \n",
    "     StructField(\"StationArea\", StringType, true), \n",
    "     StructField(\"Box\", StringType, true), \n",
    "     StructField(\"OriginalPriority\", StringType, true), \n",
    "     StructField(\"Priority\", StringType, true), \n",
    "     StructField(\"FinalPriority\", IntegerType, true), \n",
    "     StructField(\"ALSUnit\", BooleanType, true), \n",
    "     StructField(\"CallTypeGroup\", StringType, true),\n",
    "     StructField(\"NumAlarms\", IntegerType, true),\n",
    "     StructField(\"UnitType\", StringType, true),\n",
    "     StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "     StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "     StructField(\"SupervisorDistrict\", StringType, true),\n",
    "     StructField(\"Neighborhood\", StringType, true),                       \n",
    "     StructField(\"Location\", StringType, true),\n",
    "     StructField(\"RowID\", StringType, true),\n",
    "     StructField(\"Delay\", FloatType, true)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fd11400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = C:/Users/mariajose.chinchilla/OneDrive - Bosonit/Escritorio/Bosonit/Spark/datarepositorio/chapter3/data/sf-fire-calls.csv\r\n",
       "fireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Read the file using the CSV DataFrameReader\n",
    "val sfFireFile=\"C:/Users/mariajose.chinchilla/OneDrive - Bosonit/Escritorio/Bosonit/Spark/datarepositorio/chapter3/data/sf-fire-calls.csv\"\n",
    "val fireDF = spark.read.schema(fireSchema)\n",
    " .option(\"header\", \"true\")\n",
    " .csv(sfFireFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c164cff",
   "metadata": {},
   "source": [
    "## DUDA: Guardar en formato x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3074255",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Saving a DataFrame as a Parquet file or SQL table\n",
    "\n",
    "//To save as a Parquet file\n",
    "//val parquetPath = DUDA\n",
    "//fireDF.write.format(\"parquet\").save(parquetPath)\n",
    "\n",
    "//To save as a table\n",
    "//val parquetTable = \"table_fire\"\n",
    "//fireDF.write.format(\"parquet\").saveAsTable(parquetTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6f7c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Projections and filters\n",
    "val fewFireDF = fireDF\n",
    " .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\")\n",
    " .where($\"CallType\" =!= \"Medical Incident\") \n",
    "fewFireDF.show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1bd132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DistinctCallTypes|\n",
      "+-----------------+\n",
      "|               30|\n",
      "+-----------------+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Return the number of distinct types of calls\n",
    "import org.apache.spark.sql.functions._\n",
    "fireDF\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull)\n",
    " .agg(countDistinct('CallType) as 'DistinctCallTypes)\n",
    " .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf110978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|CallType                     |\n",
      "+-----------------------------+\n",
      "|Elevator / Escalator Rescue  |\n",
      "|Marine Fire                  |\n",
      "|Aircraft Emergency           |\n",
      "|Administrative               |\n",
      "|Alarms                       |\n",
      "|Odor (Strange / Unknown)     |\n",
      "|Citizen Assist / Service Call|\n",
      "|HazMat                       |\n",
      "|Watercraft in Distress       |\n",
      "|Explosion                    |\n",
      "+-----------------------------+\n",
      "only showing top 10 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "//List the distinct call types \n",
    "fireDF\n",
    " .select(\"CallType\")\n",
    " .where($\"CallType\".isNotNull)\n",
    " .distinct()\n",
    " .show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca31537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|ResponseDelayedinMins|\n",
      "+---------------------+\n",
      "|5.35                 |\n",
      "|6.25                 |\n",
      "|5.2                  |\n",
      "|5.6                  |\n",
      "|7.25                 |\n",
      "+---------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Renaming, adding, and dropping columns\n",
    "// Rename columns with the withColumnRenamed() method. We change the name of our Delay column to RespondseDelayedMins. And then we select the response times that were longer than five minutes.\n",
    "val newFireDF = fireDF.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "newFireDF\n",
    " .select(\"ResponseDelayedinMins\")\n",
    " .where($\"ResponseDelayedinMins\" > 5)\n",
    " .show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ff72326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS      |\n",
      "+-------------------+-------------------+-------------------+\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 01:51:44|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 03:01:18|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 02:39:50|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 04:16:46|\n",
      "|2002-01-11 00:00:00|2002-01-10 00:00:00|2002-01-11 06:01:58|\n",
      "+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fireTsDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//1. Convert the existing column’s data type from string to a Spark-supported timestamp.\n",
    "//2. Use the new format specified in the format string \"MM/dd/yyyy\" or \"MM/dd/yyyy hh:mm:ss a\" where appropriate\n",
    "//3. After converting to the new data type, drop() the old column and append the new one specified in the first argument to the withColumn() method.\n",
    "//4. Assign the new modified DataFrame to fire_ts_df.\n",
    "val fireTsDF = newFireDF\n",
    " .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\"))\n",
    " .drop(\"CallDate\")\n",
    " .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\"))\n",
    " .drop(\"WatchDate\")\n",
    " .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"),\n",
    " \"MM/dd/yyyy hh:mm:ss a\"))\n",
    " .drop(\"AvailableDtTm\")\n",
    "// Select the converted columns\n",
    "fireTsDF\n",
    " .select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\")\n",
    " .show(5, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d463ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "+------------------+\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "//Explore our data. We could see how many years' worth of Fire Department calls are included in the dara set\n",
    "fireTsDF\n",
    " .select(year($\"IncidentDate\"))\n",
    " .distinct()\n",
    " .orderBy(year($\"IncidentDate\"))\n",
    " .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed23e338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+------+\n",
      "|CallType                       |count |\n",
      "+-------------------------------+------+\n",
      "|Medical Incident               |113794|\n",
      "|Structure Fire                 |23319 |\n",
      "|Alarms                         |19406 |\n",
      "|Traffic Collision              |7013  |\n",
      "|Citizen Assist / Service Call  |2524  |\n",
      "|Other                          |2166  |\n",
      "|Outside Fire                   |2094  |\n",
      "|Vehicle Fire                   |854   |\n",
      "|Gas Leak (Natural and LP Gases)|764   |\n",
      "|Water Rescue                   |755   |\n",
      "+-------------------------------+------+\n",
      "only showing top 10 rows\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "//Aggregations\n",
    "\n",
    "//We will see what were the most common types of fire calls\n",
    "fireTsDF\n",
    " .select(\"CallType\")\n",
    " .where(col(\"CallType\").isNotNull)\n",
    " .groupBy(\"CallType\")\n",
    " .count()\n",
    " .orderBy(desc(\"count\"))\n",
    " .show(10, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53dd8dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|sum(NumAlarms)|avg(ResponseDelayedinMins)|min(ResponseDelayedinMins)|max(ResponseDelayedinMins)|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "|        176170|         3.892364154521585|               0.016666668|                   1844.55|\n",
      "+--------------+--------------------------+--------------------------+--------------------------+\n",
      "\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.{functions=>F}\r\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Other common DataFrame operations:\n",
    "\n",
    "//We compute the sum of alarms, the average response time and the minimum and maximum response times to all fire calls in our data set\n",
    "import org.apache.spark.sql.{functions => F}\n",
    "fireTsDF\n",
    " .select(F.sum(\"NumAlarms\"), F.avg(\"ResponseDelayedinMins\"),\n",
    " F.min(\"ResponseDelayedinMins\"), F.max(\"ResponseDelayedinMins\"))\n",
    " .show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
