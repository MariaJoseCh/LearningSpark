{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3630d5ec",
   "metadata": {},
   "source": [
    "# Counting and aggregating M&M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83e22d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries.\n",
    "# Since we are using Python, import the SparkSession and related functions from the Pyspark module.\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6364b116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a SparkSession using the SparkSession APIs.\n",
    "# If one does not exist, then create an instance.\n",
    "# There can only be one SparkSession per JVM.\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"PythonMnMCount\")\n",
    "        .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7199e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the M&M data set filename from the command-line arguments.\n",
    "mnm_file = \"C:/Users/mariajose.chinchilla/OneDrive - Bosonit/Escritorio/Bosonit/Spark/datarepositorio/chapter2/py/src/data/mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151fe7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file into a Spark DataFrame using the CSV format \n",
    "# by inferring the schema and specifying that the file contains a header, \n",
    "# which provides column names for comma-separated fields.\n",
    "mnm_df = (spark.read.format(\"csv\")\n",
    "         .option(\"header\", \"true\")\n",
    "         .option(\"inferSchema\", \"true\")\n",
    "         .load(mnm_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3681d",
   "metadata": {},
   "source": [
    "# Practicando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65807212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   TX|   Red|   20|\n",
      "|   NV|  Blue|   66|\n",
      "|   CO|  Blue|   79|\n",
      "|   OR|  Blue|   71|\n",
      "|   WA|Yellow|   93|\n",
      "|   WY|  Blue|   16|\n",
      "|   CA|Yellow|   53|\n",
      "|   WA| Green|   60|\n",
      "|   OR| Green|   71|\n",
      "|   TX| Green|   68|\n",
      "|   NV| Green|   59|\n",
      "|   AZ| Brown|   95|\n",
      "|   WA|Yellow|   20|\n",
      "|   AZ|  Blue|   75|\n",
      "|   OR| Brown|   72|\n",
      "|   NV|   Red|   98|\n",
      "|   WY|Orange|   45|\n",
      "|   CO|  Blue|   52|\n",
      "|   TX| Brown|   94|\n",
      "|   CO|   Red|   82|\n",
      "+-----+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mostramos los datos que hemos cargado\n",
    "mnm_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b634d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|State|Color|\n",
      "+-----+-----+\n",
      "|   TX|  Red|\n",
      "|   NV|  Red|\n",
      "|   CO|  Red|\n",
      "|   CO|  Red|\n",
      "|   CO|  Red|\n",
      "|   NV|  Red|\n",
      "|   WA|  Red|\n",
      "|   WY|  Red|\n",
      "|   WA|  Red|\n",
      "|   UT|  Red|\n",
      "|   CA|  Red|\n",
      "|   UT|  Red|\n",
      "|   WA|  Red|\n",
      "|   AZ|  Red|\n",
      "|   CA|  Red|\n",
      "|   CO|  Red|\n",
      "|   OR|  Red|\n",
      "|   CO|  Red|\n",
      "|   CA|  Red|\n",
      "|   WA|  Red|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos la columna de estado y color donde el color es rojo\n",
    "prueba_df = mnm_df.select(\"State\", \"Color\").filter(col(\"Color\")== \"Red\")\n",
    "prueba_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54e0f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99999"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cuento los registros \n",
    "mnm_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7efc6557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Count|\n",
      "+-----+------+-----+\n",
      "|   TX|   Red|   20|\n",
      "|   NV|  Blue|   66|\n",
      "|   CO|  Blue|   79|\n",
      "|   OR|  Blue|   71|\n",
      "|   WA|Yellow|   93|\n",
      "|   WY|  Blue|   16|\n",
      "|   CA|Yellow|   53|\n",
      "|   WA| Green|   60|\n",
      "|   OR| Green|   71|\n",
      "|   TX| Green|   68|\n",
      "+-----+------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tomo los 10 primeros\n",
    "mnm_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09457e2d",
   "metadata": {},
   "source": [
    "# Ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a624fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the DataFrame high-level APIs. Note that we don't use RDDs at all. \n",
    "# Because some of Spark's functions return the same object, we can chain functions calls.\n",
    "# 1. Select from the DataFrame the fields \"State\", \"Color\", and \"Count\".\n",
    "# 2. Since we want to group each state and its M&M color count, we use groupBy()\n",
    "# 3. Aggregate counts of all colors and groupBy() State and Color\n",
    "# 4. orderBy() in descending order\n",
    "count_mnm_df = (mnm_df\n",
    "               .select(\"State\", \"Color\", \"Count\")\n",
    "               .groupBy(\"State\", \"Color\")\n",
    "               .agg(count(\"Count\").alias(\"Total\")) \n",
    "               .orderBy(\"Total\", ascending= False)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1201ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|WA   |Green |1779 |\n",
      "|OR   |Orange|1743 |\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|CA   |Green |1723 |\n",
      "|CO   |Yellow|1721 |\n",
      "|CA   |Brown |1718 |\n",
      "|CO   |Green |1713 |\n",
      "|NV   |Orange|1712 |\n",
      "|TX   |Yellow|1703 |\n",
      "|NV   |Green |1698 |\n",
      "|AZ   |Brown |1698 |\n",
      "|WY   |Green |1695 |\n",
      "|CO   |Blue  |1695 |\n",
      "|NM   |Red   |1690 |\n",
      "|AZ   |Orange|1689 |\n",
      "|NM   |Yellow|1688 |\n",
      "|NM   |Brown |1687 |\n",
      "|UT   |Orange|1684 |\n",
      "|NM   |Green |1682 |\n",
      "|UT   |Red   |1680 |\n",
      "|AZ   |Green |1676 |\n",
      "|NV   |Yellow|1675 |\n",
      "|NV   |Blue  |1673 |\n",
      "|WA   |Red   |1671 |\n",
      "|WY   |Red   |1670 |\n",
      "|WA   |Brown |1669 |\n",
      "|NM   |Orange|1665 |\n",
      "|WY   |Blue  |1664 |\n",
      "|WA   |Yellow|1663 |\n",
      "|WA   |Orange|1658 |\n",
      "|NV   |Brown |1657 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CO   |Brown |1656 |\n",
      "|UT   |Blue  |1655 |\n",
      "|AZ   |Yellow|1654 |\n",
      "|TX   |Orange|1652 |\n",
      "|AZ   |Red   |1648 |\n",
      "|OR   |Blue  |1646 |\n",
      "|UT   |Yellow|1645 |\n",
      "|OR   |Red   |1645 |\n",
      "|CO   |Orange|1642 |\n",
      "|TX   |Brown |1641 |\n",
      "|NM   |Blue  |1638 |\n",
      "|AZ   |Blue  |1636 |\n",
      "|OR   |Green |1634 |\n",
      "|UT   |Brown |1631 |\n",
      "|WY   |Yellow|1626 |\n",
      "|WA   |Blue  |1625 |\n",
      "|CO   |Red   |1624 |\n",
      "|OR   |Brown |1621 |\n",
      "|TX   |Blue  |1614 |\n",
      "|OR   |Yellow|1614 |\n",
      "|NV   |Red   |1610 |\n",
      "|CA   |Blue  |1603 |\n",
      "|WY   |Orange|1595 |\n",
      "|UT   |Green |1591 |\n",
      "|WY   |Brown |1532 |\n",
      "+-----+------+-----+\n",
      "\n",
      "Total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "# Show the resulting aggregations for all the states and colors; a total count of each color per state.\n",
    "# Note show() is an action, which will trigger the above query to be executed.\n",
    "count_mnm_df.show(n=60, truncate=False)\n",
    "print(\"Total Rows = %d\" % (count_mnm_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5d8e8",
   "metadata": {},
   "source": [
    "## EXTRA TEST. Explain method\n",
    "Como ejercicio extra investigamos sobre el plan l√≥gico que se sigue\n",
    "haciendo uso de la API de Dataframe y de SparkSQL para poder comparar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ba44ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['Total DESC NULLS LAST], true\n",
      "+- Aggregate [State#17, Color#18], [State#17, Color#18, count(Count#19) AS Total#125L]\n",
      "   +- Project [State#17, Color#18, Count#19]\n",
      "      +- Relation [State#17,Color#18,Count#19] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "State: string, Color: string, Total: bigint\n",
      "Sort [Total#125L DESC NULLS LAST], true\n",
      "+- Aggregate [State#17, Color#18], [State#17, Color#18, count(Count#19) AS Total#125L]\n",
      "   +- Project [State#17, Color#18, Count#19]\n",
      "      +- Relation [State#17,Color#18,Count#19] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [Total#125L DESC NULLS LAST], true\n",
      "+- Aggregate [State#17, Color#18], [State#17, Color#18, count(Count#19) AS Total#125L]\n",
      "   +- Relation [State#17,Color#18,Count#19] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [Total#125L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(Total#125L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=380]\n",
      "      +- HashAggregate(keys=[State#17, Color#18], functions=[count(Count#19)], output=[State#17, Color#18, Total#125L])\n",
      "         +- Exchange hashpartitioning(State#17, Color#18, 200), ENSURE_REQUIREMENTS, [plan_id=377]\n",
      "            +- HashAggregate(keys=[State#17, Color#18], functions=[partial_count(Count#19)], output=[State#17, Color#18, count#139L])\n",
      "               +- FileScan csv [State#17,Color#18,Count#19] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/mariajose.chinchilla/OneDrive - Bosonit/Escritorio/Boso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<State:string,Color:string,Count:int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_mnm_df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d013050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['Total DESC NULLS LAST], true\n",
      "+- 'Aggregate ['State, 'Color], ['State, 'Color, 'COUNT('Count) AS Total#160]\n",
      "   +- 'UnresolvedRelation [mnm_table], [], false\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "State: string, Color: string, Total: bigint\n",
      "Sort [Total#160L DESC NULLS LAST], true\n",
      "+- Aggregate [State#17, Color#18], [State#17, Color#18, count(Count#19) AS Total#160L]\n",
      "   +- SubqueryAlias mnm_table\n",
      "      +- View (`mnm_table`, [State#17,Color#18,Count#19])\n",
      "         +- Relation [State#17,Color#18,Count#19] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [Total#160L DESC NULLS LAST], true\n",
      "+- Aggregate [State#17, Color#18], [State#17, Color#18, count(Count#19) AS Total#160L]\n",
      "   +- Relation [State#17,Color#18,Count#19] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [Total#160L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(Total#160L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=403]\n",
      "      +- HashAggregate(keys=[State#17, Color#18], functions=[count(Count#19)], output=[State#17, Color#18, Total#160L])\n",
      "         +- Exchange hashpartitioning(State#17, Color#18, 200), ENSURE_REQUIREMENTS, [plan_id=400]\n",
      "            +- HashAggregate(keys=[State#17, Color#18], functions=[partial_count(Count#19)], output=[State#17, Color#18, count#166L])\n",
      "               +- FileScan csv [State#17,Color#18,Count#19] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/mariajose.chinchilla/OneDrive - Bosonit/Escritorio/Boso..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<State:string,Color:string,Count:int>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnm_df.createOrReplaceTempView(\"mnm_table\")\n",
    "\n",
    "spark.sql(\"\"\"SELECT State, Color, COUNT(Count) AS Total \n",
    "FROM mnm_table\n",
    "GROUP BY State, Color\n",
    "ORDER BY Total DESC\"\"\").explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e35682",
   "metadata": {},
   "source": [
    "## Ejercicio.\n",
    "Continuamos con el ejercicio anterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3fee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the above code aggregated and counted for all the states, what if we just want to see the data for a single state, e.g., CA?\n",
    "# 1. Select from all rows in the DataFrame\n",
    "# 2. Filter only CA state\n",
    "# 3. groupBy() State and Color as we did above\n",
    "# 4. Aggregate the counts for each color\n",
    "# 5. orderBy() in descending order\n",
    "# Find the aggregate count for California by filtering\n",
    "ca_count_mnm_df = (mnm_df\n",
    "               .select(\"State\", \"Color\", \"Count\")\n",
    "               .where(mnm_df.State == \"CA\")\n",
    "               .groupBy(\"State\", \"Color\")\n",
    "               .agg(count(\"Count\").alias(\"Total\")) \n",
    "               .orderBy(\"Total\", ascending= False)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b68e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|CA   |Yellow|1807 |\n",
      "|CA   |Green |1723 |\n",
      "|CA   |Brown |1718 |\n",
      "|CA   |Orange|1657 |\n",
      "|CA   |Red   |1656 |\n",
      "|CA   |Blue  |1603 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the resulting aggregation for California.\n",
    "# As above, show() is an action that will trigger the execution of the entire computation\n",
    "ca_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61d07852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State|Color |Total|\n",
      "+-----+------+-----+\n",
      "|TX   |Green |1737 |\n",
      "|TX   |Red   |1725 |\n",
      "|TX   |Yellow|1703 |\n",
      "|TX   |Orange|1652 |\n",
      "|TX   |Brown |1641 |\n",
      "|TX   |Blue  |1614 |\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Podemos repetirlo para cada uno de los estados:\n",
    "tx_count_mnm_df = (mnm_df\n",
    "               .select(\"State\", \"Color\", \"Count\")\n",
    "               .where(mnm_df.State == \"TX\")\n",
    "               .groupBy(\"State\", \"Color\")\n",
    "               .agg(count(\"Count\").alias(\"Total\")) \n",
    "               .orderBy(\"Total\", ascending= False)\n",
    "                )\n",
    "tx_count_mnm_df.show(n=10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bb029a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+\n",
      "|State|Color |avg               |\n",
      "+-----+------+------------------+\n",
      "|NV   |Brown |55.81050090525045 |\n",
      "|NV   |Red   |55.4944099378882  |\n",
      "|NV   |Orange|54.865070093457945|\n",
      "|NV   |Yellow|54.561194029850746|\n",
      "|NV   |Blue  |53.797369994022716|\n",
      "|NV   |Green |53.78739693757362 |\n",
      "+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nv_avg_mnm_df = (mnm_df\n",
    "    .select(\"State\", \"Color\", \"Count\")\n",
    "    .where(mnm_df.State == \"NV\")\n",
    "    .groupBy(\"State\", \"Color\")\n",
    "    .agg(avg(\"Count\").alias(\"avg\"))\n",
    "    .orderBy(\"avg\", ascending=False))\n",
    "\n",
    "nv_avg_mnm_df.show(n=10, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
